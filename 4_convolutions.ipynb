{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4embtkV0pNxM"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 4\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb` and `3_regularization.ipynb`, we trained fully connected networks to classify [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) characters.\n",
    "\n",
    "The goal of this assignment is make the neural network convolutional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tm2CQN_Cpwj0"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11948,
     "status": "ok",
     "timestamp": 1446658914837,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "016b1a51-0290-4b08-efdb-8c95ffc3cd01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a TensorFlow-friendly shape:\n",
    "- convolutions need the image data formatted as a cube (width by height by #channels)\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11952,
     "status": "ok",
     "timestamp": 1446658914857,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "650a208c-8359-4852-f4f5-8bf10e80ef6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28, 1) (200000, 10)\n",
      "Validation set (10000, 28, 28, 1) (10000, 10)\n",
      "Test set (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "AgQDIREv02p1"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rhgjmROXu2O"
   },
   "source": [
    "Let's build a small network with two convolutional layers, followed by one fully connected layer. Convolutional networks are more expensive computationally, so we'll limit its depth and number of fully connected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "IZYv70SvvOan"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 37
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 63292,
     "status": "ok",
     "timestamp": 1446658966251,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "noKFb2UovVFR",
    "outputId": "28941338-2ef9-4088-8bd1-44295661e628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 5.365522\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 50: 1.800873\n",
      "Minibatch accuracy: 43.8%\n",
      "Validation accuracy: 49.2%\n",
      "Minibatch loss at step 100: 1.119838\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 65.0%\n",
      "Minibatch loss at step 150: 0.675118\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 75.1%\n",
      "Minibatch loss at step 200: 0.894705\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 74.9%\n",
      "Minibatch loss at step 250: 1.199480\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 300: 0.626384\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 350: 0.541163\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 400: 0.632871\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 450: 0.994450\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 500: 0.317827\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 550: 0.656285\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 600: 0.490686\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 650: 0.288377\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 700: 0.716606\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 750: 0.531502\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 800: 0.346700\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 850: 0.695350\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 82.5%\n",
      "Minibatch loss at step 900: 0.311644\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 950: 0.224731\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 82.8%\n",
      "Minibatch loss at step 1000: 0.086831\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 82.3%\n",
      "Test accuracy: 88.7%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KedKkn4EutIK"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "The convolutional model above uses convolutions with stride 2 to reduce the dimensionality. Replace the strides by a max pooling operation (`nn.max_pool()`) of stride 2 and kernel size 2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "#patch_size = 5\n",
    "patch_size = 6\n",
    "#depth = 16\n",
    "depth = 32\n",
    "num_hidden = 64\n",
    "\n",
    "beta = 0.01\n",
    "\n",
    "dropout = 0.5\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  keep_prob = tf.placeholder(tf.float32)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    \n",
    "#    hidden_drop = tf.nn.dropout(hidden, dropout)\n",
    "    \n",
    "    pool = tf.nn.max_pool(hidden, ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "#    hidden_drop = tf.nn.dropout(hidden, dropout)\n",
    "    \n",
    "    \n",
    "    pool = tf.nn.max_pool(hidden, ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    shape = pool.get_shape().as_list()\n",
    "    \n",
    "    reshape = tf.reshape(pool, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    \n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)+\n",
    "    beta*tf.nn.l2_loss(layer3_weights) +\n",
    "    beta*tf.nn.l2_loss(layer3_biases) +\n",
    "    beta*tf.nn.l2_loss(layer4_weights) +\n",
    "    beta*tf.nn.l2_loss(layer4_biases)\n",
    "\n",
    "    )\n",
    "    \n",
    "  # Optimizer.\n",
    "\n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "#  learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "  learning_rate = tf.train.exponential_decay(0.1, global_step, 100, 0.96,staircase=True)\n",
    "    \n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 9.145397\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 11.7%\n",
      "Minibatch loss at step 10000: 1.218451\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 20000: 0.625641\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 30000: 0.247096\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 40000: 0.803514\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 50000: 0.789855\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 60000: 0.310154\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 70000: 0.383093\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 80000: 0.544057\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 90000: 0.156859\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 100000: 0.094230\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 110000: 0.321857\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.6%\n",
      "Test accuracy: 95.7%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 110001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels,keep_prob: dropout}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 10000 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klf21gpbAgb-"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a convolutional net. Look for example at the classic [LeNet5](http://yann.lecun.com/exdb/lenet/) architecture, adding Dropout, and/or adding learning rate decay.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 1.10s\n",
      "valid -> train overlap: 1098 samples\n",
      "test  -> train overlap: 1296 samples\n",
      "test  -> valid overlap: 214 samples\n",
      "[False False  True False]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import hashlib\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "train_hashes = [hashlib.sha1(x).digest() for x in train_dataset]\n",
    "valid_hashes = [hashlib.sha1(x).digest() for x in valid_dataset]\n",
    "test_hashes  = [hashlib.sha1(x).digest() for x in test_dataset]\n",
    "\n",
    "valid_in_train = np.in1d(valid_hashes, train_hashes)\n",
    "test_in_train  = np.in1d(test_hashes,  train_hashes)\n",
    "test_in_valid  = np.in1d(test_hashes,  valid_hashes)\n",
    "\n",
    "valid_keep = ~valid_in_train\n",
    "test_keep  = ~(test_in_train | test_in_valid)\n",
    "    \n",
    "valid_dataset_clean = valid_dataset[valid_keep]\n",
    "valid_labels_clean  = valid_labels [valid_keep]\n",
    "\n",
    "test_dataset_clean = test_dataset[test_keep]\n",
    "test_labels_clean  = test_labels [test_keep]\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"Time: %0.2fs\" % (t2 - t1))\n",
    "print(\"valid -> train overlap: %d samples\" % valid_in_train.sum())\n",
    "print(\"test  -> train overlap: %d samples\" % test_in_train.sum())\n",
    "print(\"test  -> valid overlap: %d samples\" % test_in_valid.sum())\n",
    "\n",
    "\n",
    "k1= np.array([1,2,3,4])\n",
    "k2 = np.array([3,5,6])\n",
    "maybe_same = np.in1d(k1,k2)\n",
    "print(maybe_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = 'notMNIST_clean.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': train_dataset,\n",
    "    'train_labels': train_labels,\n",
    "    'valid_dataset_clean': valid_dataset_clean,\n",
    "    'valid_labels_clean': valid_labels_clean,\n",
    "    'test_dataset_clean': test_dataset_clean,\n",
    "    'test_labels_clean': test_labels_clean,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "#patch_size = 5\n",
    "patch_size = 6\n",
    "#depth = 16\n",
    "depth = 32\n",
    "num_hidden = 2048\n",
    "num_hidden2 = 1024\n",
    "\n",
    "beta = 0.01\n",
    "\n",
    "dropout = 0.5\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset_clean)\n",
    "  tf_test_dataset = tf.constant(test_dataset_clean)\n",
    "  keep_prob = tf.placeholder(tf.float32)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "    \n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "    \n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "    \n",
    "    \n",
    "  add3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden,num_hidden2], stddev=0.1))\n",
    "  add3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden2]))  \n",
    "       \n",
    "  \n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden2, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    \n",
    "#    hidden_drop = tf.nn.dropout(hidden, dropout)\n",
    "    \n",
    "    pool = tf.nn.max_pool(hidden, ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "#    hidden_drop = tf.nn.dropout(hidden, dropout)\n",
    "    \n",
    "    \n",
    "    pool = tf.nn.max_pool(hidden, ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "        \n",
    "    shape = pool.get_shape().as_list()\n",
    "    \n",
    "    reshape = tf.reshape(pool, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    hidden_drop = tf.nn.dropout(hidden, dropout)\n",
    "    \n",
    "    hidden2 = tf.nn.relu(tf.matmul(hidden_drop, add3_weights) + add3_biases)\n",
    "    \n",
    "    return tf.matmul(hidden2, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)+\n",
    "    beta*tf.nn.l2_loss(layer3_weights) +\n",
    "    beta*tf.nn.l2_loss(layer3_biases) +\n",
    "     beta*tf.nn.l2_loss(add3_weights) + \n",
    "     beta*tf.nn.l2_loss(add3_biases) +\n",
    "    beta*tf.nn.l2_loss(layer4_weights) +\n",
    "    beta*tf.nn.l2_loss(layer4_biases)\n",
    "\n",
    "    )\n",
    "    \n",
    "  # Optimizer.\n",
    "\n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "#  learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "  learning_rate = tf.train.exponential_decay(0.01, global_step, 10000, 0.95,staircase=True)\n",
    "    \n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "#  optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "#  optimizer = tf.train.MomentumOptimizer(0.1,0.9).minimize(loss, global_step=global_step)\n",
    "#  optimizer = tf.train.AdamOptimizer(0.01).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 272.922119\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 11.3%\n",
      "Minibatch loss at step 10000: 30.654238\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 20000: 5.166627\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 30000: 0.969677\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 40000: 1.048527\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 50000: 0.986067\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 60000: 0.389468\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 70000: 0.404511\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 80000: 0.525409\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 90000: 0.189812\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 100000: 0.145842\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 110000: 0.345324\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 120000: 0.309222\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 130000: 0.304028\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 140000: 0.274668\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 150000: 0.730199\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 160000: 0.787662\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 170000: 0.134843\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 180000: 0.277198\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 190000: 0.632867\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 200000: 0.181884\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 210000: 0.111883\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 220000: 0.192060\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 230000: 0.783712\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 240000: 0.563968\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 250000: 0.113352\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 260000: 0.285284\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 270000: 0.462965\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 280000: 0.698468\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 290000: 0.332650\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 300000: 0.422302\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 310000: 0.952122\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 320000: 0.140412\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 330000: 0.450311\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 340000: 0.279737\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 350000: 0.545381\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 360000: 0.122820\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 370000: 0.133653\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 380000: 0.282290\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 390000: 0.279649\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 400000: 0.292609\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 410000: 0.241508\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 420000: 0.320814\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 430000: 0.249388\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 440000: 0.531247\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 450000: 0.298198\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 460000: 0.410323\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 470000: 0.147567\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 480000: 0.434925\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 490000: 0.450362\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 500000: 0.289781\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 510000: 0.559401\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 520000: 0.493824\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 530000: 0.137490\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 540000: 0.420742\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 550000: 0.218964\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 560000: 0.173816\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 570000: 0.112467\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 580000: 0.317079\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 590000: 0.096109\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 600000: 0.357709\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 610000: 0.515259\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 620000: 0.373549\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 630000: 0.171292\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 640000: 0.253984\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 650000: 0.319553\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 660000: 0.193182\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 670000: 0.314569\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 680000: 0.185425\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 690000: 0.448525\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 700000: 0.194023\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 710000: 0.153676\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 720000: 0.688020\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 730000: 0.130408\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 740000: 0.397606\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 750000: 0.418292\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 760000: 0.185051\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 770000: 0.351752\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 780000: 0.334204\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 790000: 0.580995\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 800000: 0.156672\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 810000: 0.284588\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 820000: 0.140039\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 830000: 0.413764\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 840000: 0.616901\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 850000: 0.246699\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 860000: 0.499827\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 870000: 0.092575\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 880000: 0.098349\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 890000: 0.165603\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 900000: 0.240033\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 910000: 0.120316\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 920000: 0.113202\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 930000: 0.207612\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 940000: 0.225965\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 950000: 0.166782\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 960000: 0.221881\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 970000: 0.243809\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 980000: 0.594708\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 990000: 0.127670\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 1000000: 0.466345\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1010000: 0.426612\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1020000: 0.252014\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 1030000: 0.185016\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1040000: 0.188788\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 1050000: 0.140597\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1060000: 0.277289\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1070000: 0.325220\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1080000: 0.222899\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 1090000: 0.313166\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1100000: 0.188336\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 1110000: 0.406859\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1120000: 0.242805\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1130000: 0.486776\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 1140000: 0.098218\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1150000: 0.285577\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 1160000: 0.092846\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1170000: 0.220512\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1180000: 0.255570\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 1190000: 0.330773\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 1200000: 0.347613\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1210000: 0.513201\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1220000: 0.140161\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 1230000: 0.094376\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 1240000: 0.115280\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1250000: 0.292711\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1260000: 0.145510\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1270000: 0.090617\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1280000: 0.175531\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1290000: 0.245748\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1300000: 0.593988\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1310000: 0.419824\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 1320000: 0.675174\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1330000: 0.187814\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1340000: 0.239425\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1350000: 0.217156\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1360000: 0.197856\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1370000: 0.099106\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1380000: 0.210994\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 1390000: 0.454168\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1400000: 0.317324\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 1410000: 0.158857\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1420000: 0.250082\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 1430000: 0.395728\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 1440000: 0.178662\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1450000: 0.109628\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1460000: 0.409912\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 1470000: 0.322676\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1480000: 0.157835\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1490000: 0.220907\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1500000: 0.124084\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1510000: 0.414702\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 1520000: 0.542595\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 1530000: 0.120454\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1540000: 0.278317\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1550000: 0.293004\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1560000: 0.135082\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1570000: 0.301404\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1580000: 0.346456\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1590000: 0.198129\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1600000: 0.144318\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1610000: 0.253501\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1620000: 0.198150\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1630000: 0.318472\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1640000: 0.258856\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1650000: 0.400930\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1660000: 0.538980\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 1670000: 0.182919\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 1680000: 0.298224\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 1690000: 0.120670\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 1700000: 0.266718\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1710000: 0.639285\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 1720000: 0.099555\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1730000: 0.534766\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 1740000: 0.170162\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1750000: 0.197458\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1760000: 0.326162\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1770000: 0.163185\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1780000: 0.247443\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1790000: 0.465167\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1800000: 0.220271\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1810000: 0.293431\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1820000: 0.232194\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 1830000: 0.170346\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 1840000: 0.511077\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1850000: 0.127766\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 1860000: 0.383491\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 1870000: 0.501161\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1880000: 0.300545\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 1890000: 0.259450\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 1900000: 0.200037\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1910000: 0.373911\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1920000: 0.318599\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1930000: 0.099313\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 1940000: 0.429939\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1950000: 0.119633\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 1960000: 0.141889\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 1970000: 0.140299\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 1980000: 0.093660\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 1990000: 0.242060\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2000000: 0.154137\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2010000: 0.200509\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2020000: 0.393521\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 2030000: 0.158224\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2040000: 0.210879\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 2050000: 0.181482\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2060000: 0.147507\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2070000: 0.102659\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2080000: 0.341464\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2090000: 0.275557\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2100000: 0.825028\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2110000: 0.206525\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2120000: 0.572043\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2130000: 0.400654\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2140000: 0.201072\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2150000: 0.114449\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2160000: 0.290390\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 2170000: 0.249597\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 2180000: 0.187122\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 2190000: 0.162864\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 2200000: 0.251151\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2210000: 0.097250\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2220000: 0.096510\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2230000: 0.259578\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2240000: 0.287399\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2250000: 0.102321\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2260000: 0.469245\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2270000: 0.520852\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2280000: 0.105254\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2290000: 0.364442\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2300000: 0.120543\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2310000: 0.229828\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2320000: 0.327644\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 2330000: 0.223846\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2340000: 0.180336\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2350000: 0.210873\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2360000: 0.130190\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2370000: 0.293642\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 2380000: 0.471672\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2390000: 0.094418\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2400000: 0.167694\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 2410000: 0.116677\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2420000: 0.252135\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2430000: 0.270722\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2440000: 0.402704\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2450000: 0.196367\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 2460000: 0.177126\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 2470000: 0.095030\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2480000: 0.113496\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2490000: 0.302466\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 2500000: 0.256910\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2510000: 0.114528\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2520000: 0.111257\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2530000: 0.125079\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 2540000: 0.255719\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2550000: 0.269401\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2560000: 0.423344\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 2570000: 0.264120\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2580000: 0.545493\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 2590000: 0.130366\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2600000: 0.158204\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2610000: 0.450429\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2620000: 0.288211\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2630000: 0.294409\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2640000: 0.183150\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 2650000: 0.092970\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2660000: 0.225446\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2670000: 0.104840\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2680000: 0.153647\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2690000: 0.129108\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2700000: 0.285154\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2710000: 0.461109\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2720000: 0.205304\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2730000: 0.528079\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 2740000: 0.101537\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2750000: 0.158191\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2760000: 0.229443\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2770000: 0.467837\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 2780000: 0.366028\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 2790000: 0.184803\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 2800000: 0.144562\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 2810000: 0.126669\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 2820000: 0.220738\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 2830000: 0.115855\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2840000: 0.414355\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2850000: 0.449839\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 2860000: 0.449725\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2870000: 0.558713\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 2880000: 0.516121\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2890000: 0.307243\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2900000: 0.123395\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 2910000: 0.194870\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 2920000: 0.540239\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 2930000: 0.328614\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2940000: 0.313948\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2950000: 0.853854\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2960000: 0.377879\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2970000: 0.192523\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 2980000: 0.165479\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 2990000: 0.098231\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 3000000: 0.141421\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.7%\n",
      "Test accuracy: 96.6%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3000001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels,keep_prob: dropout}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 10000 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels_clean))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "4_convolutions.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
